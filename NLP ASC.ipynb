{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae72ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "# Load English dictionary\n",
    "english_dictionary = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fa3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "from tkinter import *\n",
    "import tkinter.font as font\n",
    "from nltk import ngrams\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import wordninja\n",
    "import pickle\n",
    "from nltk import edit_distance\n",
    "# import enchant\n",
    "import eng_to_ipa as eng_to_ipa\n",
    "from nltk.util import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a325c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved unigram dictionary from the file\n",
    "with open(\"unique_unigram_list.pickle\", \"rb\") as file:\n",
    "    unigram_list = pickle.load(file)\n",
    "    \n",
    "with open(\"bigram_prob_dict_final.pickle\", \"rb\") as file:\n",
    "    bigram_probabilities = pickle.load(file)\n",
    "bigram_probabilities[('</s>', '<s>')] = 1\n",
    "    \n",
    "with open(\"unigram_ipa.pickle\", \"rb\") as file:\n",
    "    unigrams_ipa = pickle.load(file)\n",
    "\n",
    "#Load the Counter object from the file\n",
    "with open('unigrams_counter_final.pickle', 'rb') as file:\n",
    "    words_counter = pickle.load(file)\n",
    "\n",
    "\n",
    "unigrams_ipa_dict = {entry['token']: entry.get('ipa') for entry in unigrams_ipa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a8a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_word = \"\"\n",
    "\n",
    "# re patterns\n",
    "#remove url\n",
    "url_pattern_1 =r'(http[s]?://)?[a-zA-Z0-9]+([-.][a-zA-Z0-9]+)\\.[a-zA-Z]{2,3}(/\\S)?'\n",
    "url_pattern_2 = r'http\\S+|www.\\S+'\n",
    "\n",
    "#remove '-\\n' patterns\n",
    "hyphen_nl_pattern = r'(-\\n)'\n",
    "\n",
    "#remove hyphens that are found in between a word\n",
    "hyphen_pattern = r'(?<=[a-z])-(?=[a-z])'\n",
    "\n",
    "#remove digits\n",
    "digits = '\\d+'\n",
    "\n",
    "#remove \\n\n",
    "next_line = r'\\n'\n",
    "\n",
    "#remove any symbols\n",
    "symbols = r'[^\\w\\s]'\n",
    "\n",
    "#remove double spaces\n",
    "double_space = r'\\s{2}' \n",
    "\n",
    "\n",
    "def sent_preprocess(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentences_clean = []\n",
    "    for sentence in sentences:\n",
    "        cleaned_sentence = re.sub(url_pattern_1, '', sentence)\n",
    "        cleaned_sentence = re.sub(url_pattern_2, '', cleaned_sentence)\n",
    "        cleaned_sentence = re.sub(hyphen_nl_pattern, '', cleaned_sentence)\n",
    "        cleaned_sentence = re.sub(hyphen_pattern, ' ', cleaned_sentence)\n",
    "        cleaned_sentence = re.sub(next_line,' ', cleaned_sentence)\n",
    "        cleaned_sentence = re.sub(digits,'', cleaned_sentence)\n",
    "        cleaned_sentence = re.sub(symbols,'', cleaned_sentence)\n",
    "        cleaned_sentence = re.sub(double_space,' ', cleaned_sentence)\n",
    "        cleaned_sentence = cleaned_sentence.lower()\n",
    "        sentences_clean.append(cleaned_sentence)\n",
    "    return sentences_clean\n",
    "\n",
    "def unnest_list(nested_list):\n",
    "    \"\"\"Unnest a list to convert nestted token in list form into unnested one\n",
    "    \n",
    "    nested_list = [1, [2, 3], [4, [5, 6]], 7, [8, [9, 10]]]\n",
    "    \n",
    "    Example:\n",
    "\n",
    "    flat_list = unnest_list(nested_list)\n",
    "    print(flat_list)\n",
    "\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\"\"\"\n",
    "    \n",
    "    unnested = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            unnested.extend(unnest_list(item))\n",
    "        else:\n",
    "            unnested.append(item)\n",
    "    return unnested\n",
    "\n",
    "def break_down(texts):\n",
    "    \"\"\"Start from preprocess the texts by removing noises such as punctuation and lower case it. Then tokenize the texts into\n",
    "    individual words and return it in unnested list\"\"\"\n",
    "    sentences = sent_preprocess(texts)\n",
    "    \n",
    "    token = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        padded = list(pad_sequence(words, pad_left=True, left_pad_symbol=\"<s>\", pad_right=True, right_pad_symbol=\"</s>\", n=2))\n",
    "        token.append(padded)\n",
    "    \n",
    "    flat_token = unnest_list(token)\n",
    "    \n",
    "    return(flat_token)\n",
    "\n",
    "# function to obtain ipa with a word\n",
    "def get_ipa(word):\n",
    "    return unigrams_ipa_dict.get(word)\n",
    "\n",
    "#generate probability of word occuring in the corpus\n",
    "def P(word, N=sum(words_counter.values())): \n",
    "    # Returns probability of a word in vocabulary.\n",
    "    return words_counter[word] / N\n",
    "\n",
    "def initialize_dictionary_list():\n",
    "    # Clear the previous content in the dictionary_list widget\n",
    "    dictionary_list.delete(0, \"end\")\n",
    "\n",
    "    # Display the dictionary list in the dictionary_list widget\n",
    "    for word in unigram_list:\n",
    "        word_entry = f\"{word}\\n\"\n",
    "        dictionary_list.insert(END, word_entry)\n",
    "    \n",
    "def combine_funcs(*funcs):\n",
    "    \"\"\"to combine multiple function inside one command when click on the button\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    combined_func(print(), list(), max())\"\"\"\n",
    "    \n",
    "    def combined_func(*args, **kwargs):\n",
    "        for f in funcs:\n",
    "            f(*args, **kwargs)\n",
    "    return combined_func\n",
    "    \n",
    "def detect_non_word_errors():\n",
    "    \"\"\"To detect non-word error based on dictionary look up and highlight the text\"\"\"\n",
    "    # Get the content of the text widget\n",
    "    input_text = editor.get(\"1.0\", \"end\")\n",
    "    \n",
    "    # set the dictionary of known words\n",
    "    known_words = unigram_list\n",
    "    \n",
    "    # split the input text and preprocess it\n",
    "    words = break_down(input_text)\n",
    "    \n",
    "    # check if the word is a non-word error\n",
    "    for word in words:\n",
    "        if word in known_words:\n",
    "            continue\n",
    "        elif word in english_dictionary:\n",
    "            continue\n",
    "        else:\n",
    "            start_index = editor.search(word, \"1.0\", \"end\", exact=True, nocase=True)\n",
    "            if start_index:\n",
    "                end_index = f\"{start_index}+{len(word)}c\"\n",
    "                editor.tag_add(\"non-word error\", start_index, end_index)\n",
    "            \n",
    "def calculate_bigram_probability(bigram):\n",
    "    return bigram_probabilities.get(bigram, 0.0)\n",
    "\n",
    "def detect_real_word_errors():\n",
    "\n",
    "    # Get the content of the text widget\n",
    "    input_text = editor.get(\"1.0\", \"end\")\n",
    "    # set the dictionary of known words\n",
    "    # known_words = unigram_list\n",
    "    # split the input text and preprocess it\n",
    "    window_size = 2\n",
    "    min_bigram_probability = 0.00001\n",
    "    words = break_down(input_text)\n",
    "    #print(words)\n",
    "\n",
    "    for i in range(1, len(words)):\n",
    "        current_word = words[i]\n",
    "        \n",
    "        # Check bigram probability\n",
    "        if i > 0:\n",
    "            if current_word not in unigram_list:\n",
    "                continue\n",
    "            previous_word = words[i-1]\n",
    "            if i < len(words)-1:\n",
    "                next_word = words[i+1]\n",
    "            else: pass\n",
    "            bigram = list(ngrams([previous_word, current_word,next_word], window_size))\n",
    "            bigram_probabilities = []\n",
    "            for bg in bigram:\n",
    "                bigram_probabilities.append(calculate_bigram_probability(bg))\n",
    "                # print(bigram,'-',bigram_probabilities)\n",
    "            avg_probability = np.mean(bigram_probabilities)\n",
    "            #print(avg_probability)\n",
    "            if avg_probability >= min_bigram_probability:\n",
    "                #print('skipped')\n",
    "                continue\n",
    "            else: print('WRONG')\n",
    "        #Find the start and end index of the word\n",
    "        start_index = editor.search(current_word, \"1.0\", \"end\", exact = True, nocase = True)\n",
    "        #curr_word_pattern = r\"\\b\" + re.escape(current_word) + r\"\\b\"\n",
    "        #start_index = editor.search(curr_word_pattern, \"1.0\", \"end\", regexp=True, exact = False)\n",
    "        #print(start_index)\n",
    "        while start_index:\n",
    "            end_index = f\"{start_index}+{len(current_word)}c\"\n",
    "        #print(end_index)\n",
    "\n",
    "        # Add a tag to highlight the real word error\n",
    "            editor.tag_add(\"real word error\", start_index, end_index)\n",
    "            start_index = editor.search(current_word, end_index, \"end\", exact=True, nocase=True)\n",
    "            \n",
    "def generate_word_candidates(event):\n",
    "    global clicked_word\n",
    "    \n",
    "    # Get the index of the clicked word\n",
    "    index = editor.index(\"@%s,%s wordstart\" % (event.x, event.y))\n",
    "    \n",
    "    # Get the word at the clicked index\n",
    "    clicked_word = editor.get(index + \" wordstart\", index + \" wordend\").lower()\n",
    "    \n",
    "    # Define corpus and bigram_probabilities\n",
    "    corpus = unigram_list\n",
    "    global bigram_probabilities\n",
    "    \n",
    "    # Find the index of the mispelled word in the sentence \n",
    "    sentence = editor.get(\"1.0\", \"end-1c\")\n",
    "    words = break_down(sentence)\n",
    "    misspelled_index = words.index(clicked_word)\n",
    "    \n",
    "    candidates = []\n",
    "    # Generate word candidates using edit distance and bigram probability \n",
    "    for word in corpus:\n",
    "        if len(word) <= 7:\n",
    "            if edit_distance(word, clicked_word, transpositions=True) <= 1:\n",
    "                candidates.append(word)\n",
    "        else:\n",
    "            if edit_distance(word, clicked_word, transpositions=True) <= 2:\n",
    "                candidates.append(word)\n",
    "    \n",
    "    probabilities = {}\n",
    "    for candidate in candidates:\n",
    "        # Get previous word for bigram probabilities computation\n",
    "        previous_word = words[misspelled_index - 1]\n",
    "        bigram_prob = calculate_bigram_probability((previous_word,candidate))\n",
    "        probabilities[candidate] = bigram_prob\n",
    "    \n",
    "    sorted_dict = {k: v for k, v in sorted(probabilities.items(), key=lambda x: x[1],reverse=True)}\n",
    "    probabilities_list = list(sorted_dict.keys())\n",
    "    \n",
    "    \n",
    "    # Clear the existing text in the correction label widget\n",
    "    suggested_candidates.delete(0, \"end\")\n",
    "\n",
    "    # Generate the word candidates in the correction label widget\n",
    "    for candidate in probabilities_list:\n",
    "        suggested_candidates.insert(\"end\", candidate + '\\n')\n",
    "\n",
    "def generate_real_word_candidates(event):\n",
    "    global clicked_word\n",
    "    \n",
    "    # Get the index of the clicked word\n",
    "    index = editor.index(\"@%s,%s wordstart\" % (event.x, event.y))\n",
    "    \n",
    "    # Get the word at the clicked index\n",
    "    clicked_word = editor.get(index + \" wordstart\", index + \" wordend\").lower()\n",
    "    clicked_word_lower = clicked_word.lower()\n",
    "    \n",
    "    # Define corpus and bigram_probabilities\n",
    "    corpus = unigram_list\n",
    "    global bigram_probabilities\n",
    "    \n",
    "    # Find the index of the mispelled word in the sentence \n",
    "    sentence = editor.get(\"1.0\", \"end-1c\")\n",
    "    words = break_down(sentence)\n",
    "    misspelled_index = words.index(clicked_word_lower)\n",
    "    \n",
    "    candidates = []\n",
    "    word_ipa = eng_to_ipa.convert(eng_to_ipa.convert(clicked_word_lower))\n",
    "    for word in corpus:\n",
    "        ed = edit_distance(word, clicked_word_lower, transpositions=True)\n",
    "        if len(word) <= 7:\n",
    "            if ed <= 1:\n",
    "                candidates.append(word)\n",
    "            if ed <=4:\n",
    "                w_ipa = get_ipa(word)\n",
    "                if w_ipa is not None:\n",
    "                    ed_ipa = edit_distance(w_ipa, word_ipa)\n",
    "                    if ed_ipa ==0:\n",
    "                        candidates.append(word)    \n",
    "        else:\n",
    "            if ed <= 2:\n",
    "                candidates.append(word)\n",
    "                            \n",
    "    candidates = list(set(candidates))\n",
    "    \n",
    "    probabilities = {}\n",
    "    for candidate in candidates:\n",
    "        # Get previous word for bigram probabilities computation\n",
    "        previous_word = words[misspelled_index - 1]\n",
    "        next_word = words[misspelled_index + 1]\n",
    "        prob = P(candidate)*calculate_bigram_probability((previous_word,candidate))*calculate_bigram_probability((candidate,next_word))\n",
    "        probabilities[candidate] = prob\n",
    "                \n",
    "    sorted_dict = {k: v for k, v in sorted(probabilities.items(), key=lambda x: x[1],reverse=True)}\n",
    "    probabilities_list = list(sorted_dict.keys())\n",
    "      \n",
    "    # Clear the existing text in the correction label widget\n",
    "    suggested_candidates.delete(0, \"end\")\n",
    "    \n",
    "    for candidate in probabilities_list:\n",
    "        suggested_candidates.insert(\"end\", candidate + \"\\n\")\n",
    "        \n",
    "def replace_word_with_candidate(event):\n",
    "    global clicked_word\n",
    "    \n",
    "    candidate_index = suggested_candidates.curselection()\n",
    "    \n",
    "    if candidate_index:\n",
    "        clicked_candidate = suggested_candidates.get(candidate_index)\n",
    "        clicked_candidate = clicked_candidate.strip()\n",
    "        \n",
    "        sentence = editor.get(\"1.0\", \"end\")\n",
    "        \n",
    "        updated_text = sentence.replace(clicked_word, clicked_candidate)\n",
    "    \n",
    "        # Clear the editor and insert the updated text\n",
    "        editor.delete(\"1.0\", \"end\")\n",
    "        editor.insert(\"end\", updated_text)\n",
    "        \n",
    "def dictionary_search():\n",
    "    search_word = search_text.get(1.0, \"end\").strip().lower()\n",
    "    \n",
    "    if search_word:\n",
    "        found = False\n",
    "        dictionary_list.selection_clear(0, 'end')\n",
    "        for index in range(dictionary_list.size()):\n",
    "            word = dictionary_list.get(index)\n",
    "            if search_word == word.lower().strip():\n",
    "                dictionary_list.selection_set(index)\n",
    "                dictionary_list.see(index)\n",
    "                dictionary_list.activate(index)\n",
    "                dictionary_list.itemconfig(index, bg = 'yellow')\n",
    "                found = True\n",
    "            else:\n",
    "                dictionary_list.itemconfig(index, bg = 'white')\n",
    "                                  \n",
    "wn = Tk()\n",
    "wn.geometry(\"1000x1000\")\n",
    "wn.configure(bg='azure2')\n",
    "wn.title(\"Spell Checker\")\n",
    "\n",
    "searchWord = StringVar()\n",
    "\n",
    "headingFrame1 = Frame(wn, bg=\"gray91\", bd=5)\n",
    "headingFrame1.place(relx=0.05, rely=0.01, relwidth=0.9, relheight=0.1)\n",
    "\n",
    "headingLabel = Label(headingFrame1, text=\"Automatic Spelling Correction System\", fg='grey19', font=('Courier', 20, 'bold'))\n",
    "headingLabel.place(relx=0, rely=0, relwidth=1, relheight=1)\n",
    "\n",
    "# Legend\n",
    "Label(wn, text='Legend: Red colour = Non-word error', bg='azure2', font=('Italian', 12)).place(x=20, y=130)\n",
    "Label(wn, text='Yellow colour = Real-word error', bg='azure2', font=('Italian', 12)).place(x=82, y=170)\n",
    "\n",
    "# Editor section\n",
    "Label(wn, text='Please input sentence', bg='azure2', font=('Courier', 12)).place(x=20, y=220)\n",
    "\n",
    "editor = Text(wn, height=12, width=106, font=('calibre', 12, 'normal'))\n",
    "editor.place(x=20, y=250)\n",
    "\n",
    "# Configure a tag for non-word and real word errors\n",
    "editor.tag_configure(\"non-word error\", background=\"red\")\n",
    "editor.tag_configure(\"real word error\", background = \"yellow\")\n",
    "\n",
    "# Bind the function to the wrong word click event\n",
    "editor.tag_bind(\"non-word error\", \"<Button-1>\", generate_word_candidates)\n",
    "editor.tag_bind(\"real word error\", \"<Button-1>\", generate_real_word_candidates)\n",
    "\n",
    "# Dictionary List section\n",
    "dictionary_label = Label(wn, text='Dictionary List:', bg='azure2', font=('Courier', 12))\n",
    "dictionary_label.place(x=20, y=480)\n",
    "\n",
    "dictionary_list = Listbox(wn, height=7, width=50, font=('calibre', 12, 'normal'))\n",
    "dictionary_list.place(x=20, y=500)\n",
    "\n",
    "# Initialize the dictionary list when run GUI \n",
    "initialize_dictionary_list()\n",
    "\n",
    "# Search Section\n",
    "search_label = Label(wn, text = 'Search:', bg = 'azure2', font = ('Courier', 12))\n",
    "search_label.place(x = 20, y = 650)\n",
    "\n",
    "search_text = Text(wn, height = 2, width = 20, font = ('calibre', 12, 'normal'))\n",
    "search_text.place(x = 20, y = 675)\n",
    "\n",
    "# Search Button\n",
    "search_button = Button(wn, text = 'Search', bg='honeydew2', fg='black', width=15, height=1, command = dictionary_search)\n",
    "search_button['font'] = font.Font(size = 12)\n",
    "search_button.place(x = 20, y = 725)\n",
    "\n",
    "# Check button\n",
    "check_button = Button(wn, text='Check', bg='honeydew2', fg='black', width=15, height=1, \n",
    "                      command=combine_funcs(detect_non_word_errors, detect_real_word_errors))\n",
    "check_button['font'] = font.Font(size=14)\n",
    "check_button.place(x=780, y=525)\n",
    "\n",
    "# Section to display corrected words\n",
    "suggested_candidates_label = Label(wn, text='Candidate Words:', bg='azure2', font=('Courier', 12))\n",
    "suggested_candidates_label.place(x=500, y=480)\n",
    "\n",
    "suggested_candidates = Listbox(wn, height=7, width=25, font=('calibre', 12, 'normal'))\n",
    "suggested_candidates.place(x=500, y=500)\n",
    "suggested_candidates.bind(\"<<ListboxSelect>>\", replace_word_with_candidate)\n",
    "\n",
    "wn.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14d18a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
